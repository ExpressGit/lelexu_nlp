计算机 研究 与 发展 
 JOURNALOFCOMPUTERRESEARCHANDDEVELOPMENT 
 1999 年 第 36 卷 第 9 期 Vol.36 No.91999 
 
 
 
 一种 基于 数据 融合 的 多 话筒 语音 识别方法 
 赵以宝 　 王祁 　 聂伟 　 孙圣 和 
 摘 　 要 　 识别率 和 对 环境 的 适应能力 是 一个 语音 识别系统 的 两个 重要 性能 ， 常见 的 提高 语音 识别率 的 方法 大多 通过 改进 声音 模型 来 获得 较 高 的 识别率 ， 这 往往 造成 声音 模型 的 复杂化 以及 模型 训练 的 困难 . 另外 ， 在 说话 人 和 麦克风 位置 不 固定 等 情况 下 ， 这些 方法 识别 效果 往往 很差 . 文中 提出 了 一种 用 多 话筒 分别 识别 一个 语音 ， 并用 数据 融合 技术 对 识别 结果 进行 处理 的 语音 识别方法 . 初步 的 实验 结果表明 该 方法 不仅 可以 提高 系统对 环境 的 适应能力 ， 而且 在 单个 声音 模型 识别率 不高 的 情况 下 ， 仍然 能 得到 较 高 的 识别率 . 
 关键词 　 语音 识别 ， 数据 融合 ， 多 话筒 
 中图法 分类号 　 TP391.4 
 AMETHODOFMULTI - MICROPHONESPEECHRECOGNITIONBASEDONDATAFUSION 
 ZHAOYi - Bao , WANGQi , NIEWei , andSUNSheng - He 
 ( DepartmentofAutomaticTestandControl , HarbinInstituteofTechnology , Harbin150001 ) 
 Abstract 　 Recognitionaccuracyandadaptabilityistwoofthemostimportantcapacityofaspeechrecognitionsystem . Ageneralmethodtoimprovespeechrecognitionaccuracyoftenfocusesonimprovingacousticmodeltoobtainahigherrecognitionaccuracy , whichoftenleadstoacomplexmodelanddifficultmodeltraining . Inaddition , inthecaseofunfixedpositionofspeakertomicrophone , itsperformanceisoftenverybad . Anewspeechrecognitionmethodisbroughtforward , whichusesmulti - microphonetorecognizeChinesesyllablesseparately , anddatafusiontechniquetoprocesstherecognitionresults . Thepreliminaryexperimentshowsitnotonlycanimprovethesystemadaptabilitytoenvironment , butalsocanreachahighersystemrecognitionaccuracywithaloweraccuracyofeachacousticmodel . 
 Keywords 　 speechrecognition , datafusion , multi - microphone 
 1 　 引言 
 　 　 识别率 和 对 环境 的 适应能力 是 语音 识别系统 的 两个 重要 性能 . 近年来 ， 人们 提出 各种各样 的 语音 识别方法 ， 常见 的 提高 识别率 的 方法 一般 都 着眼于 改进 声音 模型 来 获得 较 高 的 识别率 ， 这 往往 造成 声音 模型 的 复杂化 以及 模型 训练 的 困难 . 另外 ， 常见 的 语音 识别方法 大多数 都 局限于 安静 环境 、 说话 人 对于 麦克风 的 距离 较 近且 位置 相对 固定 等 条件 下 的 语音 识别率 提高 的 研究 . 这些 方法 在 环境 复杂 、 说话 人 和 麦克风 的 位置 、 距离 不 固定 的 情况 下 往往 效果 很差 ［ 1 , 2 ］ . 
 　 　 数据 融合 技术 是 近年来 信息处理 中 比较 热门 的 技术 ［ 3 ， 4 ］ ， 是 指 对 来自 同一个 信源 的 不同 观察 结果 进行 处理 ， 以 获得 对 被 观察 事物 客观 认识 的 一种 方法 . 人类 在 观察 事物 的 时候 ， 往往 采用 听 、 看 等 多种 方法 来 获得 对 一个 事物 的 信息 ， 然后 ， 由 大脑 做出 最终 判断 ， 从而 达到 对 该 事物 的 客观 认识 . 数据 融合 技术 实际上 是 对 人 认识 世界 的 一种 模仿 . 
 　 　 正是 基于 数据 融合 这种 模仿 人类 大脑 处理 信息 的 思想 ， 本文 提出 了 一种 基于 数据 融合 的 多 话筒 汉语 语音 音节 识别方法 ， 通过 多个 话筒 分别 采集 声音 数据 ， 对 每 一个 话筒 分别 建立 声音 模型 ， 分别 识别 ， 然后 用 数据 融合 技术 对 各个 模型 的 识别 结果 进行 处理 ， 以 达到 提高 最终 识别率 和 对 环境 适应能力 的 目的 . 和 基于 单一 话筒 的 识别系统 相比 ， 该 方法 不仅 具有 在 各个 单独 声音 模型 识别率 不高 的 情况 下 ， 仍 可以 获得 较 高 的 音节 识别率 的 优点 ， 而且 ， 由于 采用 多 话筒 技术 ， 一方面 可以 较 好 地 克服 说话 方向 、 轻重 不同 等 所 造成 的 识别率 下降 问题 ， 另外 还 降低 了 对 各个 模块 的 识别率 的 要求 ， 减轻 了 声音 模型 的 训练 困难 . 实验 结果 证明 了 该 方法 有效性 . 
 2 　 多 话筒 语音 识别 的 原理 
 　 　 多 话筒 语音 识别 的 原理 如图 1 所示 . 声音 数据 经由 麦克风 采集 ， 被 送到 各自 的 特征提取 器中 提取 特征 ， 提取 出来 的 特征 被 送到 各自 的 声音 模型 进行 识别 ， 得出 各个 模型 的 初步 识别 结果 di ， 这些 初步 识别 结果 被 作为 候选 送入 融合 中心 进行 数据 融合 ， 融合 中心 根据 一定 的 融合 算法 对 候选 结果 进行 处理 ， 得到 最后 的 识别 结果 t . 
 
 图 1 　 多 话筒 语音 识别 的 原理 
 2.1 　 声音 模型 
 　 　 本文 的 声音 模型 采用 作者 提出 的 一种 改进 的 递归 神经网 — — 时间 标签 递归 神经网 ( TTRNN ) 来 对 汉语 音节 进行 分类 . 时间 标签 递归 神经网 结构 如图 2 所示 ， 这是 一个 一阶 时延 的 TTRNN . 其中 ， Time - Tag 单元 为 时间 标签 发生器 ， 为 每 一帧 输入 u ( t ) 产生 一个 时间 标签 . 
 
 图 2 　 时间 标签 的 递归 神经网络 
 　 　 语音 的 每 一帧 u ( t ) 以及 前 一帧 所 产生 的 反馈 输出 x ( t ) 被 输入 TTRNN ， 得出 在 时刻 t 时 输入 u ( t ) 在 反馈 输入 为 x ( t ) 时 属于 某个 分类 的 概率 Pk ( u ( t ) ) ， 以及 时延 反馈 输出 x ( t + 1 ) . 则 整个 时序 模式 u 属于 某个 分类 的 概率 为 
 Pk ( u ) = pk ( u ( 1 ) ) × pk ( u ( 2 ) ) × … × pk ( u ( n ) ) = pk ( u ( t ) ) 
 ( 1 ) 
 　 　 图 2 中 在 输出 节点 上 的 圆圈 表示 计算 式 ( 1 ) 的 过程 . 
 　 　 用 TTRNN 对 汉语 音节 进行 分类 ， 就是 要求 一个 汉语 音节 属于 各个 分类 的 概率 ， 根据 概率 的 不同 ， 可以 确定 该 汉语 音节 属于 哪 一类 . 由式 ( 1 ) 知 ， 若 要求 Pk ( u ) , 只 需求 出 Pk ( u ( t ) ) 即可 ， 而 这 可以 由 TTRNN 来 得到 . 
 2.2 　 融合 算法 
 　 　 前端 的 声音 模块 对 输入 进行 初步 识别 ， 得到 初步 的 识别 结果 di , i = 1 , 2 , Λ ， N ， 组成 候选 集 D ， 被 送到 融合 中心 进行 最后 的 判决 ， 得到 最终 识别 结果 t . 我们 用 Hj , j = 1 , 2 , Λ , m 表示 m 个类 ， 其中 Hj , j = 1 , … , m - 1 表示 有 信号 假设 类 ， 而 第 m 个类 Hm 表示 无 信号 假设 类 ［ 2 ， 5 ， 6 ］ . 
 　 　 设 各个 声音 模块 是 统计 独立 的 ， 融合 中心 在 候选 集 D 的 基础 上 根据 一定 的 融合 算法 得到 整个 系统 的 最终 识别 结果 ， 即 
 t = f ( d1 , d2 , … , dN ) 
 ( 2 ) 
 设 
 
 ( 3 ) 
 为 Hj 的 概率 似然比 ， 其中 j = 1 , … , m - 1 ， 根据 最大 似然比 判决 准则 ， 则 融合 中心 的 判决 规则 为 
 
 ( 4 ) 
 　 　 由式 ( 4 ) 可知 ， 要 想 用 该 判决 规则 进行 数据 融合 ， 只 要求 出 Lj ( D ) 即可 . 下面 讨论 怎样 求 Lj ( D ) . 设 
 S1 = ｛ i ｜ di = j , i = 1 , … , N ｝ 
 S2 = ｛ i ｜ di = m , i = 1 , … , N ｝ 
 S3 = ｛ i ｜ di = l , i = 1 , … , N , l ≠ j ≠ m ｝ 
 ( 5 ) 
 　 　 则 有 
 
 ( 6 ) 
 其中 PiDjj = P ( di = j / Hj ) 为 前端 声音 模块 i 正确 做出 j 类 判决 的 概率 ； PiMjm = P ( di = m / Hj ) 为 前端 声音 模块 i 将 j 判决 为 无 信号 m 类 的 概率 ； PiEjl = P ( di = l / Hj ) 为 前端 声音 模块 i 将 j 错 判决 为 l 类 的 概率 . 
 同理 有 
 
 ( 7 ) 
 其中 PiFmj = P ( di = j / Hm ) 为 前端 声音 模块 i 将 无 信号 m 判决 为 j 类 的 概率 , j ∈ S1 ； PiDmm = P ( di = m / Hm ) 为 前端 声音 模块 i 正确 判决 为 无 信号 m 的 概率 ； PiEml = P ( di = l / Hm ) 为 前端 声音 模块 i 将 无 信号 m 错 判决 为 l 类 的 概率 , l ∈ S3 . 
 由式 ( 3 ) ， ( 6 ) ， ( 7 ) 有 
 
 ( 8 ) 
 其中 PiDjj ， PiMjm ， PiEjl ， PiFmj ， PiDmm ， PiEml 可以 通过 统计 得到 . 
 3 　 实验 及 结果 分析 
 　 　 本 实验 研究 了 用 3 个 话筒 来 实现 汉语 语音 音节 的 识别 问题 ， 实验 时 ， 用 3 台 插 有 声卡 的 计算机 同时 对 一个 人 的 发音 进行 录音 ， 话筒 放置 在 说话 人 的 正前 、 偏左 、 偏右 3 个 位置 ， 且 在 录音 时 不 要求 说话 人 固定不动 . 本 实验 共 采集 了 10 个 男性 和 10 个 女性 所念 的 0 ～ 9 共 10 个 数字 的 汉语 孤立 发音 作为 训练 和 测试数据 ， 采样 频率 采用 常见 声卡 都 支持 的 11025Hz ， 每个 采样 占 16Bit . 语音 数据 经 读入 后 提取 出 每 一个 拼音 的 语音 数据 ， 然后 进行 特征提取 . 特征提取 按 如下 过程 进行 ： 首先 对 语音 进行 预 加重 ， 然后 对 每 一个 拼音 进行 分帧 ， 以 220 点为 一帧 ， 帧 间 叠接 110 点 ， 接着 对 每 帧 信号 加 HAMMING 窗 ， 窗长 为 256 点 ， 然后 计算 特征 ， 最后 得到 如下 一个 特征 矢量 ： 15 个 MelCepstrum 系数 、 帧 能量 、 帧 过 零率 、 帧 平均 能量 、 能零积 、 能零比 共 20 维 特征 矢量 . 最后 对 每 一个 音节 的 特征 进行 长度 规整 ， 得到 最终 的 音节 特征 . 
 　 　 对 3 个 话筒 的 数据 分别 建立 3 个 TTRNN 模型 进行 训练 ， 训练 结束 后 ， 用 测试 语料 分别 测试 各个 模型 ， 得到 识别 结果 . 
 　 　 由于 本 实验 是 识别 10 个 数字 ， 所以 有 10 个 分类 ， m = 10 . 在 本 实验 中 ， 我们 把 数字 0 定义 为 第 m 分类 ， 作为 无 信号 分类 ［ 6 ］ ， 则 由式 ( 6 ) 、 式 ( 7 ) 可知 ： PiDjj 实际上 是 前端 第 i 个 声音 模型 把 输入 为 数字 j 时 判决 为 j 的 概率 ， 即 ， 其中 N ( Ij = j ) 为 输入 数字 j 时 声音 模型 识别 为 j 的 个数 ， N ( Ij ) 为 输入 到 声音 模型 的 数字 j 的 总 的 个数 . 这 可以 通过 统计 得到 ， 因此 ， 不难 得到 PiDjj . 同样 的 ， 我们 可以 得到 PiMjm ， PiEjl ， PiFmj ， PiDmm ， PiEmi ， 如表 1 ～ 3 所示 . 
 表 1 　 话筒 1 的 识别率 及 错识率 
 
 　 0123456789 
 00.80 . 100000.1000 
 10100000000 
 20010000000 
 30.100 . 10.50 . 100.10 . 100 
 40.1000 . 10.500 . 10.200 
 50.100000 . 7000.10 . 1 
 60000001000 
 70000000100 
 8000.1000000 . 90 
 900000000.300 . 7 
 
 表 2 话筒 2 的 识别率 及 错识率 
 
 　 0123456789 
 00.8000000 . 2000 
 10.20 . 800000000 
 20010000000 
 30.100 . 20.50 . 100.1000 
 40.10000 . 600.10 . 200 
 5000000.80000 . 2 
 60000000.900 . 10 
 70000000100 
 8000.1000000 . 90 
 900000000.100 . 9 
 
 表 3 话筒 3 的 识别率 及 错识率 
 
 　 0123456789 
 00.30 . 100000.6000 
 10100000000 
 20010000000 
 3000.20 . 60.100 . 1000 
 400000.600 . 20.200 
 5000000.80 . 1000.1 
 60000001000 
 70000000100 
 8000.1000000 . 90 
 900000000.200 . 8 
 
 　 　 有 了 这些 数据 后 ， 即可 根据 式 ( 8 ) 和 判决 规则 ( 4 ) 实现 3 个 声音 模型 识别 结果 的 数据 融合 ， 得到 最终 识别 结果 . 本 实验 共 测试 了 4 组 数据 T1 ， T2 ， T3 ， T4 ， 测试 结果 如表 4 所示 . 在 表 4 中 ， 上面 4 行是 每 一组 数据 对于 每 一个 声音 模型 单独 识别 的 准确率 及 3 个 模型 的 平均 识别率 ， 最 下面 一行 是 经过 融合 的 识别率 ， 从表 4 可以 看出 ， 通过 数据 融合 ， 可以 很 好 地 提高 语音 的 识别率 . 
 表 4 融合 前后 系统 识别率 
 
 　 　 T1T2T3T4 
 融合 前 话筒 160% 60% 60% 60% 
 话筒 250% 50% 50% 80% 
 话筒 360% 60% 60% 70% 
 平 　 均 56.7% 56.7% 56.7% 70% 
 融合 后 　 70% 60% 80% 90% 
 
 4 　 结束语 
 　 　 识别率 和 对 环境 的 适应能力 是 评价 语音 识别系统 好坏 的 两个 重要 参数 ， 关于 提高 其 性能 的 方法 现在 已经 有 很多 ， 但 大多 是 通过 改进 声音 模型 来 获得 较 好 地 识别率 和 对 环境 适应能力 . 本文 在 数据 融合 技术 的 基础 上 ， 提出 一种 多 话筒 语音 识别 技术 ， 通过 数据 融合 来 实现 多个 话筒 识别 结果 的 互补 矫正 ， 以 提高 整个 系统 的 识别率 . 初步 的 实验 结果表明 ： 本 方法 不仅 能够 很 好 地 提高 系统 的 环境 适应能力 ， 而且 在 各个 单独 模块 识别率 不高 的 情况 下 ， 本 方法 仍 可以 得到 较 高 的 系统 识别率 . 
 　 　 当然 本 方法 存在 诸如 硬件 投资 较大 、 占用 较 多 的 内存 和 运算 时间 等 缺点 ， 但 从 目前 来看 ， 随着 技术 的 发展 ， 这些 缺点 将 不再 成为 主要 障碍 . 而 其用 简单 的 方法 获得 较 高 的 识别率 和 对 环境 较 好 的 适应能力 等 优点 将 使得 该 方法 在 人 机智 能 接口 、 智能 机器人 、 网络 会议 等 众多 领域 得到 很 好 的 应用 . 
 作者简介 ： 赵以宝 ， 男 ， 1969 年 6 月生 ， 博士 研究生 ， 主要 研究 方向 为 语音 识别 、 神经网络 、 自然语言 处理 . 
 赵以宝 ， 男 ， 1969 年生 ， 博士 研究生 ， 主要 研究 方向 为 语音 识别 、 神经网络 、 自然 语音 处理 . 
 王祁 ， 男 ， 1944 年生 ， 教授 ， 博士生 导师 ， 主要 研究 方向 为 智能 测试 理论 与 技术 、 传感器 信息处理 . 
 聂伟 ， 男 ， 1960 年生 ， 博士 研究生 ， 主要 研究 方向 为 数据 融合 ， 智能 测试 理论 与 技术 . 
 孙圣 和 ， 男 ， 1937 年生 ， 教授 ， 博士生 导师 ， 主要 研究 方向 为 计算机 测试 与 控制 、 信号处理 与 系统 辨识 . 
 作者 单位 ： 哈尔滨工业大学 自动化 测试 与 控制 系 　 哈尔滨 　 150001 
 参考文献 
 1 　 　 LinQetal . Microphonearrayandspeakeridentification . IEEETrans . Speech & AudioProc , 1994 , 4 ( 2 ) : 622 ～ 629 
 2 　 　 杨行峻 等 . 语音 信号 数字 处理 . 北京 ： 电子 工业 出版社 . 1995 
 ( YangXingjunetal . SpeechSignalDigitProcess ( inChinese ) . Beijing : ElectricalIndustryPublisher.1995 ) 
 3 　 　 BaekW , BommareddyS . Optimalm - arydatafusionwithdistributedsensors . IEEETransonAES.1995 , 31 ( 3 ) : 1150 ～ 1152 
 4 　 　 ChairmZ , VarshneyPK . Optimaldatafusioninmultiplesensordetectionsystem . IEEETransonAES.1986 , 22 ( 1 ) : 98 ～ 101 
 5 　 　 聂伟 . 基于 假设检验 理论 的 数据 融合 算法 研究 ［ 博士论文 ］ . 哈尔滨工业大学 , 哈尔滨 , 1998 
 ( NieWei . Researchofdatafusionalgorithmsbasedonhypothesistestingtheory ［ PhDDissertation ］ ( inChinese ) . HarbinInstituteofTechnology , Harbin , 1998 ) 
 6 　 　 段凤增 . 信号 检测 理论 . 哈尔滨 ： 哈尔滨工业大学 出版社 . 1988 
 ( DuanFengzeng . SignalDetectionTheory ( inChinese ) . HarbinInstituteofTechnologyPublisher.1988 , 60 ～ 103 ) 
 原稿 收到 日期 ： 1998 - 12 - 03 ； 修改稿 收到 日期 ： 1999 - 03 - 16 . 
