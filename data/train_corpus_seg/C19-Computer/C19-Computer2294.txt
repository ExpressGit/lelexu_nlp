计算机 研究 与 发展 
 JOURNALOFCOMPUTERRESEARCHANDDEVELOPMENT 
 1999 年 第 36 卷 第 5 期 Vol.36 No.51999 
 
 
 
 一种 基于 等价 的 联盟 演化 机制 
 徐晋晖 　 石 纯一 
 摘要 　 联盟 是 多 Agent 之间 一种 重要 的 合作 方法 . 多数 方法 没有 考虑 联盟 的 演化 问题 ， 难以避免 大量 的 计算 ； 而且 对于 联盟 值 是 已知 的 假设 也 是 不 实际 的 . 文中 给出 了 联盟 问题 的 等价 性 和 相应 的 联盟 演化 机制 ， 不 通过 对 联盟 值 预先 计算 ， 可 求得 联盟 问题 的 解 ， 可以 降低 计算 复杂度 . 与 Shehory & Kraus 的 工作 相比 引入 了 联盟 的 等价 和 演化 ， 放松 了 对 联盟 值 已知 的 假设 限制 . 
 关键词 　 联盟 ， 联盟 值 ， 等价 ， 演化 
 中图法 分类号 　 TP18 
 AMECHANISMOFCOALITIONEVOLVEMENT 
 BASEDONEQUIVALENCE 
 XUJin - HuiandSHIChun - Yi 
 ( DepartmentofComputerScience , TsinghuaUniversity , Beijing 　 100084 ) 
 Abstract 　 Coalitionisanimportantcooperativemethodinmulti - agentsystems . Mostofthemethodsdon ' tconsiderevolvementofcoalition , soitisdifficulttoavoidamassofcomputation , andassumptionaboutcoalitionvalueknownisn ' trealistic . Inthepaperhere , equivalenceofcoalitionandmechanismofevolvementarepresented , whichcanobtainsolutionofcoalitionbynon - computingofcoalitionvalueandmayreducecomputationalcomplexity . Theworkofthepaperintroducesequivalenceandevolvementofcoalition , andreleasesrestrictionofassumptionaboutcoalitionvalueknown , comparedwiththeworkofShehory & Kraus . 
 Keywords 　 coalition , coalitionvalue , equivalence , evolvement 
 1 　 引 　 　 言 
 　 　 自 1993 年 文献 ［ 1 ］ 到 文献 ［ 3 ］ 提出 联盟 方法 以来 ， 已 取得 了 一定 的 进展 . 通过 联盟 可以 提高 Agent 求解 问题 的 能力 ， 获得 更 多 的 报酬 ， 因而 联盟 是 多 Agent 系统 ( MAS ) 的 重要 合作 方法 . 
 1.1 　 问题 的 描述 
 　 　 设 Agent 集 N = { A1 , A2 , … , An } ， 资源 集 Q = { ( q1 , q2 , … , qn ) } ， 其中 qi = ( q1i , q2i , … , qkii ) ， qji 表示 Ai 第 j 种 资源 的 数量 ； 任务 集 T = { T1 , T2 , … , Tn } ， 其中 Ti = { t1i , t2i , … , tmii } 是 Ai 的 任务 集 ， tji 是 Ai 的 第 j 个 任务 ， 对 每 一个 任务 有 对应 的 资源 需求 说明 ； 每 一个 Agent 开始 都 持有 一定 的 资源 . 
 　 　 MAS 的 合作 是 如何 在 Agent 之间 进行 资源 和 任务 的 重组 ， 使得 每 一个 Agent 既能 完成 任务 ， 又 能 节省 资源 取得 满意 的 报酬 ？ 这 可 通过 联盟 方法 来 完成 . 
 　 　 一个 联盟 C 可以 用 〈 Nc , qc , Q ′ c , Tc , T ′ c , V ( c ) , Uc 〉 来 描述 ， 其中 Nc 是 N 的 子集 ， qc 是 C 拥有 的 资源 ， Q ′ c 是 资源分配 的 结果 ， Tc 是 C 的 任务 集合 ， T ′ c 是 任务分配 的 结果 ， V ( c ) 是 联盟 的 值 ， Uc = ( u1 , … , u | c | ) 是 V ( c ) 对 C 成员 的 一个 分配 . 
 　 　 联盟 问题 是 求 一个 满足 稳定性 要求 的 { U , CS } ， ( U , CS ) 为 问题 求解 的 一个 中间状态 或 最后 结果 ， 其中 联盟 结构 CS = { C1 , C2 , … , Cp } 是 N 的 一个 划分 ， U = ( u1 , u2 , … , un ) 是 每个 Agent 所得 报酬 的 描述 . 
 　 　 函数 V 是 2N → R 的 映射 ， 如果 对 N 的 子集 S ， T ， 当 S ∩ T = ⅵ 眨 有 V ( S ∪ T ) ≥ V ( S ) + V ( T ) ， 称 V 满足 超加性 ， 否则 V ( S ∪ T ) < V ( S ) + V ( T ) ， 称 V 满足 次加性 ； 在 超加 情况 下 所有 的 Agent 应 组成 一个 大 联盟 ， 最后 的 CS = { N } ； 相反 在 次加 情况 下应互 不结盟 ， 最后 的 CS = { { A1 } , { A2 } , … , { An } } . 通常 以 Agent 通过 联盟 合作 带来 的 额外 效用 作为 联盟 的 值 ， 一般 有 V ( { Ai } ) = 0 . 
 1.2 　 联盟 的 形成 过程 
 　 　 联盟 的 形成 过程 ： ① 联盟 结构 CS 的 产生 ； ② 求解 联盟 值 ， 将 联盟 结构 每 一个 可能 的 联盟 的 资源 和 任务 进行 组合 分配 ， 求得 相应 的 联盟 值 ； ③ 将 联盟 值 在 成员 之间 进行 分配 ， 求得 一个 稳定 的 U . 这 3 步是 互相 交互 的 ， 需 不断 反复 求得 一个 符合 稳定性 要求 的 { U , CS } . 
 　 　 作为 一种 联盟 方法 应 满足 最小 性质 要求 ： 
 　 　 ( 1 ) 方法 的 有效性 . 指 通过 联盟 带来 的 额外 效用 不 应该 比 形成 联盟 所 需 的 通信 和 计算资源 开销 小 ； 
 　 　 ( 2 ) 结果 的 稳定性 . 有 个人 、 群体 、 联盟 3 种 理性 要求 ， 即 ① 个人 理性 公式 ui ≥ V ( { Ai } ) , ② 群体 理性 公式 是 对于 ， 有 ∑ Ai ∈ Sui = V ( S ) ， ( 有 的 文章 中 公式 是 ∑ Ai ∈ Nui = V ( N ) ， 这 只 对 超加性 适用 ) ， ③ 联盟 理性 公式 是 ， 对于 ， 有且 ∑ Ai ∈ Tui ≥ V ( T ) ， 这 是 强 理性 要求 ， 往往 难以 保证 . 
 　 　 ( 3 ) 计算 的 分布 性 . 计算 和 通信 的 分布 ， 防止 通信 瓶颈 和 瘫痪 点 现象 的 发生 . 
 　 　 ( 4 ) 过程 的 简单 性 . 要求 得 一个 满意 的 结果 采用 穷尽 所有 可能 的 方案 是 不 现实 的 ， 因为 这是 一个 NP 问题 . 
 　 　 有 的 文章 中 也 提到 对称性 ［ 4 ］ ， 非减 性 ［ 5 ］ 等 . 
 1.3 　 相关 的 工作 分析 
 　 　 Shehory & Kraus ［ 2 ， 6 ， 7 ］ , Zlotkin & Rosenschein ［ 4 ］ , Ketchpel ［ 3 ， 8 ］ 和 Sandholm & Lesser ［ 9 ， 10 ］ 的 工作 没有 考虑 联盟 的 演化 ， 每当 新 的 任务 加入 任务 集时 ， 需要 依 形成 算法 重新 结盟 ， 而 当 任务 求解 完成 后 ， 联盟 解体 ， 这样 势必 有 大量 的 计算 和 通信 开销 ； 并且 所有 的 方法 均 假定 联盟 的 值 是 预先 求得 的 ， 但是 联盟 值 的 预先 计算 是 困难 的 ， 因为 只有 最后 合作 完成 ， 才能 实际 确定 联盟 的 值 . 
 　 　 针对 这些 问题 ， 本文 首先 给出 了 联盟 等价 的 定义 和 相应 的 命题 ， 进而 依 联盟 等价 给出 了 联盟 的 基本 过程 、 匹配 方法 、 调整 策略 等 演化 机制 . 
 2 　 联盟 等价 性 
 　 　 依 N 人 合作 对策 中 策略 等价 ， 引入 联盟 问题 的 等价 性 . 对策 论中 
 　 　 对策 ( N , v ) 与 ( N , u ) 称为 策略 等价 的 ， 如果 存在 正数 a 及 实数 β 1 , β 2 , … , β n , 使 
 
 　 　 这里 的 v 和 u 是 联盟 值 函数 ， 并 限定 V ( { Ai } ) = 0 . 
 　 　 定义 1 . 设有 联盟 问题 P1 和 P2 ， 对应 的 联盟 值 函数 是 V1 和 V2 ， 如果 有 正数 a ， 使 
 
 那么 称 P1 和 P2 在 联盟 值 函数 上 等价 . 
 　 　 命题 1 . 设 P1 和 P2 在 联盟 值 函数 上 等价 ， 如果 已 求得 P2 的 一个 解 ( U2 , CS2 ) ， 那么 ( aU2 , CS2 ) 是 P1 的 一个 解 . 
 　 　 联盟 问题 是 多解 的 ， 核心 、 核 、 稳定 集等 对策 解是 集合 的 含义 ， 这里 指 Shapley 值 、 核心 、 核 、 稳定 集等 的 一种 . 命题 1 从 不同 的 解 定义 来 证明 . 
 　 　 例 1 . 设 N = { 1 , 2 , 3 } ， 对于 P1 有 V1 ( { 1 } ) = V1 ( { 2 } ) = V1 ( { 3 } ) = 0 ， V1 ( { 1 , 2 } ) = V1 ( { 1 , 3 } ) = V1 ( { 2 , 3 } ) = 4 ， V1 ( { 1 , 2 , 3 } ) = 8 ， 对于 P2 有 V2 ( { 1 } ) = V2 ( { 2 } ) = V2 ( { 3 } ) = 0 ， V2 ( { 1 , 2 } ) = V2 ( { 1 , 3 } ) = V2 ( { 2 , 3 } ) = 2 ， V2 ( { 1 , 2 , 3 } ) = 4 ， 可见 对 ， 有 V1 ( S ) = 2V2 ( S ) ， 那么 P1 和 P2 在 联盟 值 函数 意义 上 等价 . 对于 P2 求得 Shapley 值 意义 上 的 解是 （ U2 = ( 4 / 3 , 4 / 3 , 4 / 3 ) , CS2 = { { 1 , 2 , 3 } } ） ， 并且 解 ( U2 , CS2 ) 恰好 也 在 核心 、 核 和 稳定 集中 . 可以 验证 （ U1 = 2 ( 4 / 3 , 4 / 3 , 4 / 3 ) , CS1 = { { 1 , 2 , 3 } } ） 是 P1 在 Shapley 值 意义 上 的 解 ， 同时 属于 P1 的 核心 、 核 和 稳定 集中 . 
 　 　 寻求 得 等价 联盟 问题 的 解 ， 要 依赖于 联盟 值 函数 的 预先 求得 ， 而 这 是 困难 的 ， 但 可 将 联盟 值 与 任务 代价 联系 起来 讨论 . 
 　 　 任务 代价 函数 E 是从 Agent （ 或 联盟 ） 的 任务 集到 实数 集 R 的 映射 . 
 　 　 约定 的 联盟 值 是 Agnet 之间 通过 合作 所 带来 的 额外 效益 ， 也 就是 任务 代价 的 降低 . 对 CN ， 有 
 V ( C ) = ∑ i ∈ CE ( Ti ) - E ( TC ) . 
 　 　 这里 Ti 是 Ai 的 任务 集 ， TC = Ui ∈ CTi 是 联盟 C 的 任务 集 . 
 　 　 当 V1 ( C ) = aV2 ( C ) 有 
 ∑ i ∈ CE ( T1i ) - E ( T1C ) = a （ ∑ i ∈ CE ( T2i ) - E ( T2C ) ） = a （ ∑ i ∈ CE ( T2i ) ） - aE ( T2C ) 　 　 CN . 
 　 　 这里 T1i 是 P1 中 Ai 的 任务 集 . 
 　 　 定义 2 . 设有 联盟 问题 P1 和 P2 ， 如果 存在 正数 a ， 使 
 ∑ i ∈ CE ( T1i ) - E ( T1C ) = a （ ∑ i ∈ CE ( T2i ) - E ( T2C ) ） = a （ ∑ i ∈ CE ( T2i ) ） - aE ( T2C ) 　 　 CN , 
 那么 称 P1 和 P2 在 代价 上 等价 . 
 　 　 命题 2 . 设 P1 和 P2 在 代价 上 等价 ， 那么 命题 1 的 结果 仍 成立 . 
 　 　 判断 联盟 问题 代价 等价 是 困难 的 ， 因为 要 对 N 的 所有 子集 进行 比较 ， 但 比 依 联盟 值来 判断 等价 进 了 一步 . 
 　 　 为了 方便 ， 我们 限定 ： 如果 对 i ∈ N ， 当 E ( T1i ) = aE ( T2i ) ， 对 CN 有 E ( T1C ) = aE ( T2C ) 成立 ， 这种 限定 称为 E 约束 . 
 　 　 命题 3 . 设有 联盟 问题 P1 和 P2 ， 满足 E 约束 ， 如果 存在 正数 a ， 使 
 C ( T1i ) = aC ( T2i ) 　 　 对 i ∈ N ， 
 那么 P1 和 P2 在 代价 上 等价 . 
 　 　 这时 ， 就 可以 根据 每个 Ai 的 任务 集 ， 来 判断 联盟 是否 等价 . 
 　 　 命题 4 . P1 和 P2 在 联盟 值上 等价 当且 仅 当 P1 和 P2 在 代价 上 等价 . 
 　 　 如果 两个 联盟 问题 等价 ， 那么 在 已知 一个 联盟 问题 的 解 ， 就 可以 直接 计算 出 另 一个 联盟 问题 的 解 . 
 3 　 联盟 演化 
 　 　 联盟 演化 与 联盟 历史 有关 ， 令 联盟 历史 ( { 联盟 问题 ， 联盟 结果 } ) 中 ， 每个 { 联盟 问题 ， 联盟 结果 } 称为 联盟 的 一段 历史 ， 这里 联盟 问题 指 ( ( HE1 , ε 1 ) , ( HE2 , ε 2 ) , … , ( HEn , ε n ) ) ， 其中 ( HEi , ε i ) 是 对 Ai 的 描述 ， HEi 是 历史 代价 ， 联盟 结果 是 ( U , CS ) . 
 　 　 ε i = HEi / ( ∑ Aj ∈ NHEj ) 是 等价 匹配 范围 . 根据 启发式 知识 ， 给 每 一个 Agent 指定 一个 适当 的 范围 提高 匹配 的 成功率 ， 其所失 要 比 通过 联盟 形成 来 求得 一个 结果 所 付出 的 计算 和 通信 的 开销 小 . U 中 不 保存 具体 的 数值 ， 而是 一个 比例 ， 且 对 所有 的 C ∈ CS ， 有 ∑ i ∈ Cui = 1 ， 这样 只有 最后 合作 求解 完成 ， 才 根据 相应 的 比例 进行 联盟 值 的 分配 . 
 3.1 　 联盟 演化过程 
 　 　 步骤 1 . 每 一个 Agent 计算 任务 代价 ， 将 结果 通知 其他 的 Agent ； 
 　 　 步骤 2 . 与 保存 的 联盟 历史 进行 等价 匹配 ： 
 ① 如果 匹配 成功 ， 那么 以 成功 匹配 的 历史 的 结果 ， 作为 此时 联盟 问题 的 结果 ； 
 ② 如果 匹配 不 成功 ， 考虑 是否 可以 通过 调整 达到 匹配 ， 否则 调用 已有 的 联盟 形成 方法 ； 
 　 　 步骤 3 . 按 求得 的 ( U , CS ) 组成 联盟 ， 对 给定 的 任务 进行 合作 求解 ， 并 进行 联盟 值 的 实际 分配 . 如果 是 通过 联盟 形成 求得 的 结果 ， 将 相应 的 结果 保存 到 联盟 历史 中 . 
 　 　 该 过程 可以 在 MAS 环境 下 实现 . 
 3.2 　 分布式 等价 匹配 
 　 　 定义 3 . Ai 与 一段 历史 以 正数 a 为 参考 匹配 ， 是 指 目前 的 任务 代价 Ei 在 ［ ( a - ε i ) HEi , ( a + ε i ) HEi ］ 范围 内 . 
 　 　 联盟 C 与 一段 历史 以 正数 a 为 参考 匹配 ， 是 指 所有 的 联盟 成员 均 以 a 为 参考 与 该 历史 匹配 . 
 　 　 联盟 问题 与 一段 历史 以 正数 a 为 参考 匹配 ， 是 指 CS 中 的 所有 联盟 均 以 a 为 参考 与 该 历史 匹配 . 
 　 　 分布式 等价 匹配 过程 ： 
 　 　 步骤 1 . 每 一个 Agent 以 自我 为 起点 ， 计算 目前 的 Ei 与 所有 历史 的 比 a ； 
 　 　 步骤 2 . 对于 每 一段 历史 ， 判断 其 所在 联盟 内 的 其他 成员 是否 以 相应 的 a 为 参考 与 该 历史 匹配 ； 
 　 　 步骤 3 . 将 联盟 内 所有 成员 均 匹配 的 历史 与 相应 的 a ， 通知 其他 的 Agent ； 
 　 　 步骤 4 . 如果 在 所有 的 Agent 之间 存在 一个 相同 的 历史 且 a 也 相同 ， 那么 匹配 成功 . 
 3.3 　 基于 代价 转移 的 调整 
 　 　 分布 等价 匹配 步骤 4 中 ， 虽然 达 不到 完全相同 的 历史 ， 但 如果 存在 这样 的 一段 历史 ， 可以 采用 代价 转移 的 方法 ， 使 趋于 相同 . 
 　 　 这样 一段 历史 应 满足 的 条件 是 ： CS 中 只有 一个 联盟 没有 匹配 ， 且 该 联盟 成员数 较 少 ， 且 满足 可 调整 条件 . 
 　 　 可 调整 条件 ： ∑ i ∈ CEi = ∑ i ∈ Ca × HEi ， 指 虽然 个别 的 可能 不 匹配 ， 整体 是 匹配 的 . 
 　 　 每 一个 Agent 计算 相应 的 ai ， 比 a 大者 向 比 a 小者 进行 一定量 的 任务 代价 转移 ， 同时 要 对 相应 的 报酬 也 进行 转移 ， 对于 转移 的 量 在 转移 者 之间 通过 协商 机制 达到 同意 ， 一直 到 出现 匹配 为止 . 
 　 　 如果 大多数 Agent 对于 一个 历史 认为 匹配 ， 而 只有 极少数 认为 不 匹配 ， 而且 被 同意 的 Agent 认为 属于 同一 联盟 内 ， 那么 同意 者 可以 要求 不 同意 者 之间 进行 调整 ， 达到 全局 的 一致 ， 这是 启发式 知识 ， 并且 由于 可 调整 条件 保证 了 调整 的 成功 ； 在 调整 中 ， 代价 的 转移 同时 伴随 报酬 的 转移 . 
 3.4 　 联盟 形成 
 　 　 在 匹配 不 成功 ， 且 不能 进行 调整 时 ， 需要 调用 已有 的 联盟 形成 方法 来 进行 求解 . 在 联盟 演化 的 初级阶段 ， 会 经常 使用 联盟 形成 方法 ， 但 随着 联盟 历史 的 积累 ， 匹配 的 成功率 逐步提高 ， 到 一定 时候 可能 会 不 需要 联盟 形成 . 
 3.5 　 实例 分析 
 　 　 以 本文 的 例 1 为例 ， 按照 本文 的 方法 ， 如果 已有 P1 的 历史 ， 那么 当 遇到 P2 时 ， 通过 匹配 可以 发现 P2 与 P1 等价 ， 此时 可以 直接 得到 P2 的 结果 ， 而 不 需 进行 联盟 形成 算法 的 调用 . 
 4 　 结 　 　 语 
 　 　 联盟 演化 机制 的 主要 计算 是 等价 的 匹配 ， 复杂度 是 O ( m ) ， m 是 联盟 历史 的 个数 . 随着 联盟 历史 的 增多 ， 匹配 的 成功率 提高 ， 但 相应 的 复杂度 增大 ， 并且 要 大量 的 存储空间 来 支持 ， 这是 一对 矛盾 ， 可以 借鉴 CBR 的 有关 方法 . 
 　 　 本文 给出 的 演化 机制 适合 于 一般 情形 ， 不 局限于 V 满足 超加性 ， 而已 有 的 联盟 形成 方法 局限于 超加 情形 ； 所 提供 的 一种 不 通过 预先 计算 联盟 值 ， 求解 联盟 问题 解 的 方法 ； 在 匹配 成功 （ 可以 调整 ） 的 情况 下 ， 计算 复杂度 远 低于 现有 的 方法 ， 因为 现有 的 方法 不可避免 要 进行 联盟 值 计算 、 联盟 值 的 分配 ； 在 匹配 不 成功 的 情况 下 ， 仅 比 现有 的 方法 多 匹配 的 计算 . 
 　 　 对 每 一个 联盟 问题 ， 在 匹配 不 成功 的 情况 下 ， 如何 通过 合适 的 调整 方法 ， 构造 一个 等价 联盟 问题 ， 省去 调用 联盟 形成 方法 的 连续 演化 ， 是 有待 研究 的 工作 . 
 本 课题 得到 国家自然科学基金 ( 项目编号 69773026 ， 69733020 ) 和 清华大学 研究生院 博士学位 论文 基金 资助 . 
 作者简介 ： 徐晋晖 ， 男 ， 1966 年 4 月生 ， 博士 研究生 ， 研究 方向 为 多 Agent 系统 、 联盟 机制 . 石 纯一 ， 男 ， 1935 年 8 月生 ， 教授 ， 博士生 导师 ， 研究 方向 为 人工智能 应用 基础 . 
 作者 单位 ： 清华大学 计算机科学 系 　 北京 　 100084 
 参考文献 
 　 1 　 ZlotkinG , RosenscheinJS . One , two , many : Coalitionsinmulti - agentsystems . In : CastelfranchiC , PmullerJEds . FromReactiontoCognition , LectureNotesinArtificialIntelligence , Vol957 . Berlin : Springer , 1993 
 　 2 　 ShehoryO , KrausS . Coalitionformationamongautonomousagents : Strategiesandcomplexity . In : CastelfranchiC , PmullerJEds . FromReactiontoCognition , LectureNotesinArtificialIntelligence , Vol957 . Berlin : Springer , 1993.57 ～ 72 
 　 3 　 KetchpelS . Coalitionformationamongautonomousagents . In : CastelfranchiC , PmullerJEds . FromReactiontoCognition , LectureNotesinArtificialIntelligence , Vol957 . Berlin : Springer , 1993.73 ～ 88 
 　 4 　 ZlotkinG ， RosenscheinJS . Coalition , cryptographyandstability : Mechanismsforcoalitionformationintaskoriented . In : ProcAAAI - 94 . Seattle , 1994.432 ～ 437 
 　 5 　 罗翊 , 石 纯一 . Agent 协作 求解 中 形成 联盟 的 行为 策略 . 计算机 学报 ， 1997 , 20 ( 11 ) : 961 ～ 965 
 ( LuoYi , ShiChunyi . Thebehaviorstrategytoformcoalitioninagentcooperativeproblemsolving . ChineseJournalofComputers ( inChinese ) , 1997 , 20 ( 11 ) : 961 ～ 965 ) 
 　 6 　 ShehoryO , KrausS . Taskallocationviacoalitionformationamongautonomousagents . In : ProcIJCAI - 95 . Montreal , 1995.655 ～ 661 
 　 7 　 ShehoryO , KrausS . Akernel - orientedmodelforcoalitionformationingeneralenvironments : Implementationandresults . In : ProcAAAI - 96 . Portland , 1996.134 ～ 140 
 　 8 　 KetchpelS . Formingcoalitionsinthefaceofuncertainrewards . In : ProcAAAI - 94 . Seattle , 1994.414 ～ 419 
 　 9 　 SandholmTW , LesserVR . Coalitionformationamongboundedrationalagents . In : ProcIJCAI - 95 . Montreal , 1995.694 ～ 701 
 　 10 　 SandholmTW , LesserVR . Coalitionamongcomputationallyboundedagents . ArtificialIntelligence , 1997 , 94 ( 1 ) : 99 ～ 137 
 　 　 原稿 收到 日期 ： 1998 - 08 - 11 
 修改稿 收到 日期 ： 1998 - 10 - 28 
