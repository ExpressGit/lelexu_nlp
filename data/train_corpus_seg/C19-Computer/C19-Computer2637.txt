软件 学报 
 JOURNALOFSOFTWARE 
 1999 年 第 10 卷 第 8 期 Vol.10 No.81999 
 
 
 
 分布式 虚拟环境 中 基于 神经网络 的 实时 预测 
 寿黎 但 史烈 石教英 
 摘要 　 在 分布式 虚拟环境 中 , 性能 的 瓶颈 是 为 维护 主机 间 实体 行为 的 一致性 而 进行 的 通信 . 该文 针对 虚拟 场景 中 的 难 预测 对象 建立 其 状态 向量 的 神经网络 模型 , 使用 了 基于 函数 型 连接 的 神经网络 对 其 行为 进行 实时 预测 . 首先 介绍 了 函数 型 连接 的 原理 和 特点 ; 其次 , 在 对 传统 的 DR 算法 进行 描述 后 提出 了 基于 神经网络 预测 的 自 适应 DR 算法 ; 然后 给出 了 基于 该 算法 的 网络软件 结构 ; 最后 对 一个 特例 进行 了 实验 , 实验 结果表明 该 算法 可以 很 好 地 工作 . 
 关键词 　 分布式 虚拟环境 , 计算机网络 , DeadReckoning ( DR 算法 ) , 神经网络 , 函数 型 连接 . 
 中图法 分类号 　 TP 
 Real - timePredictionBasedonNeural - networksinDistributedVirtualEnvironment 
 SHOULi - danSHILieSHIJiao - ying 
 ( StateKeyLaboratoryofCAD & CGZhejiangUniversityHangzhou310027 ) 
 ( DepartmentofComputerScienceandEngineeringZhejiangUniversityHangzhou310027 ) 
 Abstract 　 Inadistributedvirtualenvironment ( DVE ) , thebottleneckofperformanceisthecommunicationamonghostswhichkeepstheconsistencyofvirtualentities . Theneural - networkmodelsofstatevectorsforunpredictableentitiesinavirtualscenearebuildinthispaper , andthefunctional - linknettoreal - timepredictionoftheirbehaviorisapplied . Firstly , theprinciplesandcharactersoffunctional - linknetareintroducedinthispaper ; secondly , afterdescriptionofthetraditionaldeadreckoning ( DR ) algorithm , anadaptiveversionofthealgorithmbasedonfunctional - linknetispresented ; thenetworksoftwarearchitecturebasedonthealgorithmisalsogiven ; finally , anexampleofthealgorithmisgivenwithexperimentaldata , whichshowsthegoodperformanceofit . 
 Keywords 　 Distributedvirtualenvironment , computernetworks , deadreckoning , neural - network , functional - linknet . 
 　 　 分布式 虚拟环境 ( distributedvirtualenvironment ) 是 指 , 在 一组 以 网络 互联 的 计算机 上 同时 运行 虚拟环境 ( VE ) 系统 的 技术 . 它 是 虚拟环境 与 网络 技术 学科 交叉 的 产物 , 可以 使 人们 自由 地 在 虚拟环境 中 实现 交互 而 不 受 其 实际 地理位置 的 制约 , 从而 可 在 许多 科研 和 应用领域 中 使用 , 如 远程 学习 、 计算机 支持 下 的 协同工作 ( CSCW ) 、 分布式 模拟 ( distributedsimulation ) 等 各种 应用 . 分布式 虚拟环境 的 理论 和 概念 还 派 生出 了 许多 新 的 领域 , 如 远程 机器人 ( telerobotics ) 、 远程 诊治 ( telemedicine ) 等 . 分布式 虚拟环境 是 目前 最 热门 的 研究 领域 之一 , 在 科学研究 、 模拟训练 、 战场 仿真 等 许多 方面 有 广阔 的 应用 前景 . 
 　 　 在 分布式 虚拟环境 中 , 最 根本 的 要求 是 每时每刻 都 要 保持 分布式系统 各 主机 间 场景 和 场景 中 各 虚拟 实体 行为 的 一致性 , 以 维护 整个 系统 的 统一 . 因此 这 就 需要 各 主机 之间 实时 地 交换 大量 的 状态 信息 , 由此 而 引起 的 通信量 往往 占 分布式 虚拟环境 实体 间 总 通信量 的 大部分 . 这 一类 通信 我们 称为 一致性 通信 . 一致性 通信 数据 的 发送者 称为 参考 系统 （ 或 标准 系统 ） , 接收者 称为 从属 系统 . 在 场景 复杂度 较 高 （ 如 数万 ～ 数十万 实体 ） 或 系统 规模 较大 （ 数百 ～ 数千台 主机 ） 的 情况 下 ［ 1 ］ , 一致性 通信 往往 会 导致 网络 环境 的 拥塞 乃至 崩溃 . 因此 , 降低 一致性 通信量 是 分布式 虚拟环境 中 的 一个 重要 研究课题 . 
 　 　 近年来 已有 许多 研究 工作 在 该 方向 上 展开 ［ 2 ］ ［ 3 ］ , 其中 常用 的 方法 是 采用 自动控制 理论 中 的 DR 算法 , 对 虚拟 场景 中 的 实体 行为 进行 预测 , 减少 一致性 通信 的 次数 , 从而 达到 降低 网络带宽 的 目的 . 它们 的 基本 思想 是 在 参考 系统 和 从属 系统 上 采用 完全一致 的 预测 算法 , 根据 虚拟 实体 的 状态 历史 , 对 下 一 时刻 的 状态 进行 预测 . 如果 预测 结果 与 实际 状态 相差不远 , 则 在 参考 系统 端 不 发送 下 一 时刻 的 一致性 数据 , 从属 系统 中下 一 时刻 的 状态 就 用 预测 所得 结果 代替 ; 反之 , 若 与 实际 相差 较 远 , 则 发送 实际 状态 的 数据 , 即 进行 一致性 通信 . 这类 预测 所 工作 的 对象 一般 有 一个 共同 的 特征 , 即 其 状态 向量 可用 一个 简单 的 时间 函数 表示 . 但是 实际 的 虚拟 场景 中 往往 存在 许多 实体 , 其 状态 向量 无法 用 一个 简单 的 函数 来 表示 . 这类 对象 一般 较 智能化 , 直接 受到 人 的 控制 , 因此 , 随意性 很大 . 对于 这 类 实体 , 传统 的 DR 算法 无能为力 , 这 就 需要 另辟 途径 来 对 其 进行 研究 . 在 本文 中 , 我们 使用 基于 函数 型 连接 的 神经网络 来 对 虚拟 实体 进行 实时 的 预测 , 得到 了 较 好 的 效果 , 大大降低 了 一致性 通信量 （ 在 本文 中 , 为了 避免 混淆 , 我们 用 网络 一词 表示 多台 主机 之间 的 计算机网络 , 而用 神经网络 一词 表示 抽象 的 人工神经网络 ） . 
 1 函数 型 连接 简介 
 　 　 在 函数 型 连接 模型 中 , 一旦 一个 节点 , 例如 , 节点 k 被 激励 , 就 会 有 许多 附加 函数 功能 也 被 激励 , 即 不仅 能 得到 节点 k 的 输出 ok , 而且 还 能 得到 f0 ( ok ) , f1 ( ok ) , ... , fn ( ok ) ［ 4 ］ . 对 函数 型 连接 的 不同 具体 要求 会 产生 不同 的 效果 . 在 本文 中 , 我们 考虑 函数 展开 模型 和 张量 （ 或称 外积 ） 模型 . 
 　 　 在 函数 展开 模型 中 , 函数 型 连接 单独 作用 在 每个 节点 上 对于 输入 模式 中 的 每个 节点 , 它 产生 相同 的 附加 函数 . 在 这种 情况 下 , 输入 x 可以 简单 地 展开 成 它 的 幂函数 , 或者 是 展开 成 n 维空间 的 正交 基 函数 的 一个 子集 , 例如 : sin π x , cos π x , sin2 π x , cos2 π x 等等 . 该 神经网络 的 作用 是 将 输入 模式 映射 到 一个 更大 的 模式 空间 . 我们 将 输入 分量 与其 展开 的 量 联系 起来 , 并用 它们 来 表达 输入 . 这样 做 没有 引入 本质性 的 新 信息 , 但 模式 表达 可以 得到 增强 . 
 　 　 在 张量 或 外积 模型 中 , 输入 模式 的 每个 分量 都 被 乘 上 整个 输入 模式 矢量 . 在 这种 情况 下 , 原来 由 分量 集合 { xi } 所 描述 的 模式 变成 { xi , xixj } ( 其中 j ≥ i ) 或 { xi , xixj , xixjxk } ( 其中 j ≥ i , k ≥ j ≥ i ) 等等 . 这样 做 没有 引入 新 的 信息 , 但是 它 可 使 神经网络 得到 联合 激励 . 
 　 　 在 这 两种 模型 中使 表达 增强 的 运算 可以 适当 地 混用 . 通过 函数 变换 后 的 神经网络 由于 其 输入 得到 了 增强 , 仅 使用 ( 规则 和 单层 神经网络 就 可 使 学习 过程 迅速 收敛 ［ 5 ］ . 对 输入 节点 个数 不 超过 5 , 样本 个数 较 少 （ 10 个 以内 ） 的 小规模 学习 问题 , 只 需 不到 100 次 即可 使 系统误差 小于 10 - 6 . 例如 , 考虑 一个 3 输入 （ x1 , x2 , x3 ) , 单 输出 ( y ) 的 学习 问题 , 7 组 学习 样本 见表 1 . 
 表 1 三 输入 单 输出 学习 样本 集 
 
 样本 序号 x1x2x3y 
 10.2160 . 10.10 . 90 
 20.3470 . 160.10 . 85 
 30.4630 . 240.10 . 80 
 40.4870 . 320.30 . 75 
 50.5130 . 400.30 . 7 
 60.5470 . 460.60 . 65 
 70.7800 . 90.60 . 6 
 
 
 　 　 可以 采用 混合型 函数 展开 项 x1 , x2 , x3 , x1 . x2 , x1 . x3 , x2 . x3 , cos ( 3 π . x2 ) , cos ( 3 π . x3 ) , cos ( 18 π . x3 . x2 ) , cos ( 13 π . x1 . x3 ) , cos ( 13 π . x1 . x2 ) , cos ( 24 π . x1 . x3 ) , cos ( 24 π . x2 . x3 ) , cos ( 24 π . x1 . x3 ) 等 14 项 , 采用 单层 拓扑 结构 即可 使 神经网络 迅速 收敛 , 如图 1 所示 . 
 
 图 1 　 三 因素 函数 型 网络 的 学习 速度 
 　 　 从图 1 中 可以 看出 , 在 多 因素 情况 下 采用 扩展 的 输入 项 , 可 使得 学习 的 收敛 速度 大大提高 , 同时 , 该 神经网络 采用 了 单层 的 结构 , 设计 简单 , 编程 方便 , 学习 时间 极短 （ 在 Pentium200MHz 机器 上 不到 1ms ） , 因此 , 可以 满足 实时 预测 的 需求 . 
 2 基于 函数 型 连接 的 预测 算法 
 　 　 在 分布式 虚拟环境 中 , 已经 有 许多 有关 虚拟 实体 状态 向量 的 预测 算法 的 研究 . 这类 算法 统称 为 DR 算法 . 一个 典型 的 DR 预测 算法 是 在 参考 系统 和 从属 系统 两端 都 使用 Kalman 预测器 ［ 6 ］ , 根据 其 运动 的 状态方程 在 每 一次 时钟 周期 时 检查 其 预测 结果 与 实际 状态 的 误差 , 如该 误差 超过 一个 约定 的 阈值 , 则 进行 一致性 通信 , 否则 省去 该次 时钟 周期 内 的 一致性 通信 . 
 　 　 在 动态 的 虚拟 场景 中 , 许多 运动 实体 常常 遵循 一定 的 规律 运动 . 但是 也 有 一些 实体 的 运动 没有 明显 的 规律 可循 , 即 无法 用 状态方程 表示 其 运动 . 举 一些 简单 的 例子 , 如 鼠标 的 移动 、 数据 手套 的 动作 等 . 这些 对象 的 运动 往往 受到 智能型 用户 的 直接 控制 , 因而 其 状态 改变 的 随意性 较大 . 换句话说 , 这 类 对象 的 状态 较难 预测 . 如果 将 这类 对象 中 的 某 一个 看做 一个 系统 , 则 往往 不 可能 找到 一个 确定 的 状态方程 来 描述 它 . 此时 , 我们 可以 求助于 神经网络 . 
 　 　 在 第 1 节中 我们 已 简单 地 介绍 了 基于 函数 型 连接 的 神经网络 . 这种 神经网络 的 优越性 使得 它 可 胜任 实时 的 预测 . 算法 的 基本原理 是 : 对于 难 预测 对象 而言 , 在 长时间 内其 运动 状态 往往 显得 较 混乱 而 无规律 , 但是 我们 有 理由 认为 （ 算法 的 实验 也 确实 表明 了 这 一点 ） 在 一段 短时间 内 , 对象 的 运动 遵循 某种 难以确定 的 规律 , 这种 规律 是 随着 时间 而 改变 的 , 但是 状态 对于 时间 的 变化 总是 连续函数 , 因此 , 在 有限 的 自变量 范围 内 , 根据 有限 个 样本 总 可以 用 若干个 确定 的 正交 基 函数 的 线性 表示 来 逼近 ［ 5 ］ . 这 也 是 函数 型 连接 的 理论 基础 . 这些 正交 基 函数 正是 函数 型 连接 中 的 函数 展开 项 . 例如 , 提供 k 组 样本 集合 { ( Xm , Xm + 1 , ... , Xm + r - 1 , ym + r ) , ( Xm + 1 , Xm + 2 , ... , Xm + r , ym + r + 1 ) , ( Xm + k - 1 , Xm + k , ... , Xm + k + r - 2 , ym + k + r - 1 ) } , 其中 ym + i 恰好 就是 Xm + i ( i = r , ... , k + r - 1 ) , 则 可以 选取 适当 的 神经网络 , 经过 学习 后 使得 神经网络 输出 向量 y ′ m + i 与 样本 集合 中 的 ym + i 一致 . 因此 可以 看出 , 这里 的 每组 样本 实际上 是 根据 前 r 个 状态 , 预测 第 r + 1 个 状态 . 由 该组 样本 训练 而成 的 神经网络 可以 用来 预测 ym + k + r 的 值 . 
 　 　 由于 对象 状态 不停 地 改变 , 这 就 需要 实时 地 对 预测器 进行 调整 , 包括 修改 学习 样本 集 并 进行 再 学习 . 这样 我们 可以 在 传统 的 DR 算法 基础 上 得到 另 一种 算法 , 这种 算法 可以 称为 基于 学习 的 自 适应 DR 算法 . 由于 自 适应 DR 算法 能 对 运动 方程 不 确定 的 对象 进行 预测 , 因此 特别 适用 于 难 预测 对象 . 
 在 给出 算法 描述 之前 我们 先对 符号 表示 作 一些 约定 : 我们 用 k 维 向量 X = ( x1 , x2 , ... , xk ) T 表示 被 考察 对象 的 状态 向量 ; 用 Xn 表示 tn 时刻 对象 的 状态 向量 . 第 i 组 学习 样本 用 含有 r + 1 个 状态 向量 的 矩阵 S ( i ) = ( Xmi , Xmi + 1 , ... , Xmi + r - 1 , Y ( i ) ) 表示 , 其 含义 是 前 r 个 状态 向量 预测 产生 函数 型 连接 的 输出 状态 向量 y ( i ) . 学习 样本 集 η 如下 : { S ( i ) | i = 1 , 2 , ... , N } . 
 　 　 整个 系统 分为 参考 端 （ 标准 端 ） 和 从属 端 . 参考 端的 预测 算法 如下 . 
 　 　 算法 1 . 参考 端的 预测 算法 
 　 　 Step1 . 用伪 随机数 构造 样本 集 η = { S ( i ) | i = 1 , 2 , ... , N } . 
 　 　 Step2 . 用 该组 样本 集合 对 神经网络 进行 训练 学习 . 
 Step3 . 将 过去 的 r 个 时间 点 的 状态 历史 序列 Xn - r + 1 , Xn - r + 2 , ... , Xn 作为 函数 型 神经网络 的 r 个 输入 , 计算 输出 向量 ( 即 预测 结果 ） n + 1 . 
 　 　 Step4 . 接收 到 下 一个 时间 同步 信号 （ tn + 1 时刻 ） , 如果 ‖ Xn + 1 - n + 1 ‖ ＞ ε , 则 将 新 状态 向量 Xn + 1 的 数据 通过 计算机网络 环境 发送到 预测 端 , 并 将 状态 Xn + 1 加入 历史 序列 , 同时 用 新 样本 
 S = ( Xn - r + 1 , Xn - r + 2 , ... , Xn , Xn + 1 ) 
 代替 η 中 最 老 的 样本 ; 否则 , 不 发送数据 , 而 将 预测 向量 n + 1 当作 tn + 1 时刻 的 状态 加入 状态 历史 序列 , 同时 用 
 S = ( Xn - r + 1 , Xn - r + 2 , ... , Xn ) 
 更新 样本 集 η . 
 　 　 Step5 . 无条件 跳转 至 Step2 , 依次 无限 循环 执行 Step2 ～ 4 各步 操作 . 
 　 　 由 算法 的 描述 可知 , 每 收到 一个 时钟 信号 , 算法 就 循环 一次 . 上述 算法 的 Step3 中 需要 忽略 最初 的 r 次 循环 , 因为 最初 r 次 循环 时 不 存在 长度 为 r 的 历史 序列 . 另外 , 每次 循环 都 要 改变 相应 序列 的 下标 . 这些 说明 同样 也 适用 于 从属 端的 算法 . 从属 端的 算法 可以 表示 如下 . 
 　 　 算法 2 . 从属 端的 预测 算法 
 　 　 Step1 . 用 与 算法 1 相同 的 伪 随机数 构造 样本 集 η = { S ( i ) i = 1 , 2 , ... , N } . 
 　 　 Step2 . 用 该组 样本 集合 对 神经网络 进行 训练 学习 . 
 　 　 Step3 . 将 过去 的 r 个 时间 点 的 状态 历史 序列 Xn - r + 1 , Xn - r + 2 , ... , Xn 作为 函数 型 神经网络 的 r 个 输入 , 计算 输出 向量 ( 即 预测 结果 ） n + 1 . 
 　 　 Step4 . 接收 到 下 一个 时间 同步 信号 （ tn + 1 时刻 ） , 如果 在此之前 收到 参考 端的 数据包 , 则 将 收到 的 新 状态 Xn + 1 加入 历史 序列 , 同时 用 新 样本 
 S = ( Xn - r + 1 , Xn - r + 2 , ... , Xn , Xn + 1 ) 
 代替 η 中 最 老 的 样本 ; 否则 , 即 未 收到 数据包 , 则 将 预测 向量 n + 1 当做 tn + 1 时刻 的 状态 加入 状态 历史 序列 , 同时 用 
 S = ( Xn - r + 1 , Xn - r + 2 , ... , Xn ) 
 更新 样本 集 η . 
 　 　 Step5 . 无条件 跳转 至 Step2 , 依次 无限 循环 执行 Step2 ～ 4 各步 操作 . 
 3 系统 的 软件结构 
 　 　 根据 上节 中 所 给出 的 算法 , 我们 可以 设计 出 相应 的 网络软件 结构 . 如图 2 所示 . 
 
 图 2 　 基于 神经网络 
 　 　 对应 于 一个 实体 i , 参考 端 主机 上 有 一个 神经网络 预测器 , 其 内部 运行 算法 1 ; 与 它 相对 应 从属 端 主机 上 必然 存在 一个 相应 的 从属 实体 i ′ 和 神经网络 预测器 , 该 预测器 执行 算法 2 ( 图中 F - LNN 是 基于 函数 型 连接 的 神经网络 的 缩写 ) . 由于 分布式 虚拟环境 中 主要 的 性能 限制 来自 网络带宽 瓶颈 , 从 该软件 结构图 可以 看出 , 采用 神经网络 预测器 的 实质 是 用 消耗 计算资源 的 方法 来 降低 对 网络资源 的 需求 . 基于 函数 型 连接 的 神经网络 具有 极高 的 收敛 速度 （ 多数 情况 ＜ 1ms ） , 因此 当 实体 个数 较大 时 , 预测 过程 所 消耗 的 单机 计算资源 仍然 不多 . 可见 , 该 预测 算法 提供 了 良好 的 可扩展性 , 对于 目前 计算机领域 内 很 热门 的 大规模 分布式 虚拟环境 ［ 3 ］ （ Large - ScaleDistributedVirtualEnvironment ） 具有 参考价值 . 
 4 实验 结果 
 　 　 由于 我们 所 关心 的 实体 行为 是 “ 难以预测 ” 的 , 实体 行为 的 宏观 表现 较 混乱 , 所以 往往 不 需要 保留 很长 的 状态 历史 序列 , 一般 只 需 不到 10 个 . 另外 , 我们 所 考察 的 虚拟 实体 在 虚拟空间 中 函数 型 连接 的 学习 过程 非常 迅速 , 在 样本 个数 不 超过 10 个 , 只 需要 100 ～ 200 次 循环 学习 即可 使 神经网络 收敛 . 当 输入 的 状态 向量 个数 不 超过 5 个 时 , 这样 的 计算 量 在 目前 的 高档 PC机 上 只 需 不到 1ms 的 时间 , 因此 该 算法 完全 可以 用于 实时 的 预测 . 
 　 　 我们 对 空间 自由度 为 2 的 鼠标 进行 了 实验 , 硬件平台 是 用 10Mbps 的 以太网 互连 的 20 台 Pentium200Mhz 的 PC机 , 软件平台 采用 MSWindows95 , 实验 对象 是 4 名 熟练 用户 . 另外 , 我们 对 同样 的 数据 使用 二次 多项式 插值 来 预测 作为 对照 . 在 该 实验 的 神经网络 预测 算法 中 , r 值取 为 2 , 样本 集所含 的 样本 个数 N 为 4 . 因此 , 我们 可以 建立 含有 二个 输入 向量 , 一个 输出 向量 的 函数 型 神经网络 . 设 两个 输入 向量 分别 为 ( xn - 1 , yn - 1 ) 和 ( xn , yn ) , 则 对 该 两个 向量 作 如下 19 维 的 混合型 函数 展开 : xn - 1 , yn - 1 , xn , yn , xn - 1 . yn - 1 , xn - 1 . xn , yn - 1 . xn , xn . yn , xn . yn - 1 , xn - 1 . yn , xn . yn , cos ( 3 π . xn - 1 ) , cos ( 3 π . yn - 1 ) , cos ( 3 π . xn ) , cos ( 3 π . yn ) , cos ( 8 π . xn - 1 . yn - 1 ) , cos ( 8 π . xn - 1 . yn ) , cos ( 13 π . xn . yn ) , cos ( 13 π . xn . yn - 1 ) , 并 实时 预测 新 的 状态 向量 ( xn + 1 , yn + 1 ) , 结果 如图 3 所示 . 
 
 图 3 　 预测 算法 对 4 个 用户 的 鼠标 使用 的 结果 
 　 　 实验 结果表明 , 该 算法 对 所有 用户 所 操纵 的 鼠标 都 能 很 好 地 进行 预测 , 而且 该 算法 的 预测 精度 优于 多项式 插值 的 预测 算法 . 产生 这种 结果 的 原因 是 由于 神经网络 预测器 能够 实时 地 修改 其权值 , 使 之 在 不同 的 时刻 进行 自 适应 . 在 模拟 实体 数目 较大 的 情况 下 （ 例如 , 103 个 ） , 算法 可以 节省 50% ～ 70% 的 一致性 通信量 , 对 所有 实体 进行 一次 预测 消耗 CPU 时间 2.4 ～ 3.0 s . 但是 对于 大规模 系统 ( 实体 数 ＞ 105 ) , 模拟 测试表明 , 消耗 在 预测 算法 上 的 计算 量 特别 巨大 , 这 就 需要 强大 的 单机 计算能力 的 支持 . 另外 , 对于 传统 DR 算法 的 预测 对象 , 即 状态 可 表示 为 显式 时间 函数 的 实体 , 该 神经网络 算法 也 可 很 好 地 进行 预测 , 本文 不再 赘述 . 
 5 结论 
 　 　 （ 1 ） 函数 型 连接 是 一种 采用 函数 并行 激励机制 的 神经网络 , 这种 神经网络 的 特点 是 采用 单层 拓扑 结构 和 δ 学习 规则 , 因而 收敛 速度 非常 高 . 本文 给出 了 一个 基于 函数 型 连接 的 神经网络 预测 算法 用于 对 分布式 虚拟环境 中 的 实体 状态 进行 实时 的 预测 , 克服 了 传统 的 DR 算法 对难 预测 对象 无法 建立 其 控制论 模型 的 缺点 . 实验 结果表明 , 对 自由度 为 二 的 鼠标 , 该 算法 可以 很 好 地 工作 . 
 　 　 （ 2 ） 在 分布式 虚拟环境 中 , 主要 的 性能 瓶颈 是 网络带宽 . 文中 所述 的 基于 函数 型 连接 的 神经网络 预测 算法 降低 了 网络带宽 的 消耗 , 有助于 提高 整个 系统 的 性能 和 可扩展性 . 
 本文 通讯联系 人 : 寿黎 但 , 杭州 310027 , 浙江大学 CAD & CG 国家 重点 实验室 
 作者简介 ： 寿黎 但 , 1974 年生 , 硕士生 , 主要 研究 领域 为 CSCW , 多媒体 , 大规模 分布式 虚拟环境 . 史烈 , 1964 年生 , 讲师 , 主要 研究 领域 为 多媒体 , 虚拟现实 . 石教英 , 1937 年生 , 教授 , 博士生 导师 , 主要 研究 领域 为 计算机 图形学 , 计算机 体系结构 , 虚拟现实 . 
 作者 单位 ： 寿黎 但 　 浙江大学 CAD & CG 国家 重点 实验室 杭州 310027 
 史烈 石教英 　 浙江大学 计算机科学 与 工程学系 杭州 310027 
 参考文献 
 1PentlandAP . Computationalcomplexityversussimulatedenvironments . ComputerGraphics , 1990 , 24 ( 2 ) : 185 ～ 192 
 2PrattDR . Asoftwarearchitecturefortheconstructionandmanagementofrealtimevirtualenvironments ［ Ph . D . Thesis ］ . Monterey , California : NavalPostgraduateSchool , 1993 
 3MacedoniaMR . Anetworksoftwarearchitectureforlargescalevirtualenvironments ［ Ph . DThesis ］ . Monterey , California : NavalPostgraduateSchool , 1995 
 4 ( 美 ) 包 约翰 . 自 适应 模式识别 与 神经网络 . 北京 : 科学出版社 , 1992 
 ( PaoYoh - han . AdaptivePatternRecognitionandNeural - networks . Massachusetts , MenloPark : Addison - WesleyPublishingCompanyInc . , 1989.192 ～ 215 ) 
 5PaoYoh - han , YoshiyasuTakefuji . Functional - linknetcomputing : theory , systemarchitecture , andfunctionalities . Computer , 1992 , 25 ( 5 ) : 76 ～ 79 
 6Baumgartner , EricT , Skaar , StevenB . Anautonomousvision - basedmobilerobot . IEEETransactionsonAutomaticControl , 1994 , 39 ( 3 ) : 493 ～ 502 
 本文 1998 - 06 - 02 收到 原稿 , 1998 - 09 - 16 收到 修改稿 
